Unit 2: Architectural Components of MCP

Core Architecture Overview--:
MCP uses a Client-Server model to connect AI apps (Hosts) to external tools/services (Servers) via Clients.

🧩 Key Components
| Component  | Role                      | Details                                                                                                 |
| ---------- | ------------------------- | ------------------------------------------------------------------------------------------------------- |
| **Host**   | User-facing AI app        | Manages user input, permissions, LLM coordination, result display. Ex: ChatGPT, Cursor, LangChain agent |
| **Client** | Connector inside the Host | 1:1 connection with Server, manages MCP protocol, translates requests/responses                         |
| **Server** | External tool/service     | Exposes tools/resources via MCP, can be local or remote, lightweight wrappers                           |

📌 Modular: 1 Host → Many Clients → Many Servers. Easy to scale.

Communication Flow (End-to-End):--

User Interaction: User sends input to Host

Host Processing: Uses LLM to understand request

Client Connects: Client inside Host connects to Server

Capability Discovery: Client asks Server “What can you do?”

Capability Invocation: Host tells Client which Server capability to use

Server Execution: Server does the work and replies

Result Integration: Client passes result to Host → LLM/User sees output

⚙️ Advantages of This Architecture
🔁 Modularity: Add/replace Servers without touching Host

➕ Scalability: Solves M×N → M+N problem

🌐 Interoperability: Any Host can work with any Server (if MCP-compliant)

🧠 Extensibility: Supports versioning & negotiation

✅ User-Safety First: Sensitive actions require approval

🔍 Discoverability: Clients can ask Servers about available capabilities

🔚 Conclusion
MCP’s architecture may seem simple, but its power lies in standardization, modularity, and flexibility. It enables real-time, intelligent interaction between AI models and external environments at scale.